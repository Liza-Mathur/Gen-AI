{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53984b06-2a1a-47b4-aa79-9b3184f14481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-6.6.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (4.7.0)\n",
      "Collecting audioop-lts<1.0 (from gradio)\n",
      "  Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.129.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==2.1.0 (from gradio)\n",
      "  Downloading gradio_client-2.1.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub<2.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl.metadata (43 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<4.0,>=1.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<13.0,>=8.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (2.10.3)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.22-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (2024.1)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7 (from gradio)\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.52.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.24.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.41.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\anaconda3\\lib\\site-packages (from gradio-client==2.1.0->gradio) (2025.3.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Collecting typing-inspection>=0.4.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from fastapi<1.0,>=0.115.2->gradio)\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.17.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.33.5->gradio)\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: shellingham in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\asus\\anaconda3\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<4.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pandas<4.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.27.1)\n",
      "Collecting click>=8.2.1 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: rich>=12.3.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\lib\\site-packages (from click>=8.2.1->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<4.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from rich>=12.3.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\asus\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-6.6.0-py3-none-any.whl (24.2 MB)\n",
      "   ---------------------------------------- 0.0/24.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/24.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/24.2 MB 2.1 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 1.6/24.2 MB 2.8 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 2.6/24.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.6/24.2 MB 3.7 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 3.4/24.2 MB 3.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/24.2 MB 3.3 MB/s eta 0:00:07\n",
      "   ------ --------------------------------- 4.2/24.2 MB 3.3 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 5.2/24.2 MB 3.0 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.0/24.2 MB 3.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.3/24.2 MB 2.9 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 6.8/24.2 MB 2.8 MB/s eta 0:00:07\n",
      "   ------------ --------------------------- 7.3/24.2 MB 3.0 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.6/24.2 MB 2.9 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 8.1/24.2 MB 2.7 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 9.2/24.2 MB 2.8 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 9.4/24.2 MB 2.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 9.7/24.2 MB 2.7 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 10.0/24.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 10.2/24.2 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 11.0/24.2 MB 2.5 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 12.1/24.2 MB 2.7 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 13.1/24.2 MB 2.8 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.4/24.2 MB 2.9 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 15.2/24.2 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 15.5/24.2 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.3/24.2 MB 3.0 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.8/24.2 MB 2.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.3/24.2 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 18.1/24.2 MB 2.9 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 18.9/24.2 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.4/24.2 MB 3.0 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.7/24.2 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.4/24.2 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.0/24.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 22.0/24.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.3/24.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.5/24.2 MB 2.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.2 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.2/24.2 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading gradio_client-2.1.0-py3-none-any.whl (55 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)\n",
      "Downloading fastapi-0.129.0-py3-none-any.whl (102 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
      "   ---------------------------------------- 0.0/553.3 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 262.1/553.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 553.3/553.3 kB 2.2 MB/s eta 0:00:00\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 12.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.0/2.9 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.3/2.9 MB 3.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.6/2.9 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.9/2.9 MB 2.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 2.4 MB/s eta 0:00:00\n",
      "Downloading orjson-3.11.7-cp313-cp313-win_amd64.whl (124 kB)\n",
      "Downloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.52.1-py3-none-any.whl (74 kB)\n",
      "Downloading typer-0.24.0-py3-none-any.whl (56 kB)\n",
      "Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Downloading brotli-1.2.0-cp313-cp313-win_amd64.whl (369 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Downloading python_multipart-0.0.22-py3-none-any.whl (24 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading uvicorn-0.41.0-py3-none-any.whl (68 kB)\n",
      "Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, typing-inspection, semantic-version, python-multipart, orjson, hf-xet, groovy, ffmpy, click, audioop-lts, annotated-doc, aiofiles, uvicorn, starlette, typer, safehttpx, huggingface-hub, fastapi, gradio-client, gradio\n",
      "\n",
      "  Attempting uninstall: brotli\n",
      "\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "   - --------------------------------------  1/21 [brotli]\n",
      "   --- ------------------------------------  2/21 [typing-inspection]\n",
      "   ----------- ----------------------------  6/21 [hf-xet]\n",
      "  Attempting uninstall: click\n",
      "   ----------- ----------------------------  6/21 [hf-xet]\n",
      "    Found existing installation: click 8.1.8\n",
      "   ----------- ----------------------------  6/21 [hf-xet]\n",
      "    Uninstalling click-8.1.8:\n",
      "   ----------- ----------------------------  6/21 [hf-xet]\n",
      "      Successfully uninstalled click-8.1.8\n",
      "   ----------- ----------------------------  6/21 [hf-xet]\n",
      "   ----------------- ----------------------  9/21 [click]\n",
      "   ------------------- -------------------- 10/21 [audioop-lts]\n",
      "   ------------------------ --------------- 13/21 [uvicorn]\n",
      "   -------------------------- ------------- 14/21 [starlette]\n",
      "   -------------------------- ------------- 14/21 [starlette]\n",
      "  Attempting uninstall: typer\n",
      "   -------------------------- ------------- 14/21 [starlette]\n",
      "    Found existing installation: typer 0.9.0\n",
      "   -------------------------- ------------- 14/21 [starlette]\n",
      "   ---------------------------- ----------- 15/21 [typer]\n",
      "    Uninstalling typer-0.9.0:\n",
      "   ---------------------------- ----------- 15/21 [typer]\n",
      "      Successfully uninstalled typer-0.9.0\n",
      "   ---------------------------- ----------- 15/21 [typer]\n",
      "   ---------------------------- ----------- 15/21 [typer]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   -------------------------------- ------- 17/21 [huggingface-hub]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   ---------------------------------- ----- 18/21 [fastapi]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   -------------------------------------- - 20/21 [gradio]\n",
      "   ---------------------------------------- 21/21 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 audioop-lts-0.2.2 brotli-1.2.0 click-8.3.1 fastapi-0.129.0 ffmpy-1.0.0 gradio-6.6.0 gradio-client-2.1.0 groovy-0.1.2 hf-xet-1.2.0 huggingface-hub-1.4.1 orjson-3.11.7 pydub-0.25.1 python-multipart-0.0.22 safehttpx-0.1.7 semantic-version-2.10.0 starlette-0.52.1 typer-0.24.0 typing-inspection-0.4.2 uvicorn-0.41.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970c9d10-917c-48d3-afbf-2c9c4858d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7345f07e-53b2-4d7d-80c9-a4bb34ce4d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text):\n",
    "    print(\"Shout has been called with \",text)\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c301283d-b46e-4f07-a7f5-0176c36dd5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with  Liza\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LIZA'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout(\"Liza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48800cce-9717-43d2-85a7-5413f2994667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs = \"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1150de99-781c-47c5-b755-1c7bc37c30ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7868/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(auth=(\"liz\", \"math\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267d7fa6-d5b1-4e91-9adc-0d02c6785dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with  howdy\n"
     ]
    }
   ],
   "source": [
    "# Adding a little more:\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message to be shouted\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    title=\"Shout\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1395b3-954d-44e1-9c4f-12a849d97b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66346635-6876-4261-a4f8-51fcc8c3a90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc07a536-97c3-4f2b-b00d-d0ced06e4178",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97e28807-1eff-41f2-9954-5d62863c9cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm doing well, thank you. How can I assist you today?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "message_gpt(\"How do you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4364a9e8-2404-49dc-bcbe-f9d2f031b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e642d9-c493-434d-a63e-e850cbe5ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7872\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7872/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message = \"You are a helpful assistant that returns output in markdown with code blocks\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "             ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0b0dc-8eee-4562-9f1f-d2759cc8c854",
   "metadata": {},
   "source": [
    "# Lets stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dc29736-6798-4562-bde4-4adcfe6f5ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d55da33-2776-46c8-af15-d9f001b6e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7873\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "223da4d7-6583-444f-a79f-543156874ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_claude(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = anthropic.chat.completions.create(\n",
    "        model='claude-sonnet-4-5-20250929',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f6ab953-5130-4500-90bd-edc48bdbcf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e97d4ee5-76a4-400c-b91a-c878cade03ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for the LLM\", lines=7)\n",
    "model_selector = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    title=\"LLMs\", \n",
    "    inputs=[message_input, model_selector], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "            [\"Explain the Transformer architecture to a layperson\", \"GPT\"],\n",
    "            [\"Explain the Transformer architecture to an aspiring AI engineer\", \"Claude\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c158c-0a6b-438f-8c21-9c7eba5aeea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
